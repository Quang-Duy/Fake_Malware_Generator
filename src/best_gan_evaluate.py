""" Evaluate and save best GAN model among save_intervals

Usage

>>> python -m src.best_gan_evaluate

"""

import logging
import os

import coloredlogs
import hydra
import numpy as np
import omegaconf
from omegaconf import DictConfig

from multiprocessing import Process, Queue

from src.common.utils import PROJECT_ROOT, MyTimer

from tensorflow.keras.models import load_model
from tensorflow.keras.layers import LeakyReLU
from sklearn.model_selection import KFold

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import precision_score, recall_score

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('h5py').setLevel(logging.ERROR)
logger = logging.getLogger(__name__)
coloredlogs.install(level=logging.DEBUG, logger=logger)


class GANEvaluator:
    """ Contains GAN evaluators: SVM, Random Forest, GaussianNB"""

    def __init__(self, param: DictConfig,
                 svm_param: DictConfig,
                 modelmodule: DictConfig,
                 trainer: DictConfig,
                 datamodule: DictConfig,
                 num_opcode_unique: int) -> None:
        self.eval_param = param
        self.svm_param = svm_param
        self.modelmodule = modelmodule
        self.trainer = trainer
        self.datamodule = datamodule
        self.factor = num_opcode_unique / 2

    def make_train_data_with_label(self, real_data: np.ndarray,
                                   gen_samples: np.ndarray):
        idx = np.random.randint(low=0, high=real_data.shape[0],
                                size=self.trainer.batch_size)
        real = real_data[idx]

        train_data = np.concatenate((real, gen_samples))
        label = np.array(
            [1] * self.trainer.batch_size + [0] * self.trainer.batch_size
        )

        return train_data, label

    def load_saved_model(self, model_num_epoch: int):
        path = os.path.join(PROJECT_ROOT, self.trainer.save_path,
                            'save_interval')
        file_name = str(self.eval_param.architecture + '_' +
                        self.eval_param.family + '_' +
                        str(model_num_epoch) + '.hdf5')
        path_to_model = path + '/' + file_name

        if not os.path.exists(path):
            raise FileNotFoundError(
                f"Model path {path_to_model} was not found. "
                f"Current dir: {os.getcwd()}")

        generator = load_model(path_to_model)
        return generator

    def generate(self, generator) -> np.ndarray:
        random_normal_size = (self.trainer.batch_size,
                              self.modelmodule.model.latent_dim)
        noise = np.random.normal(0, 1, size=random_normal_size)
        gen_samples = generator.predict(noise)
        gen_samples = (gen_samples + 1) * self.factor
        gen_samples = np.rint(gen_samples).astype(int)

        new_shape = (self.trainer.batch_size,
                     self.datamodule.datasets.train.max_file_len)
        gen_samples = np.reshape(gen_samples, newshape=new_shape)
        return gen_samples

    def svm(self, train_data, label):
        """ Train and Evaluate SVM model on real and fake data

        Args:
            train_data:
            label:

        Returns:

        """
        k_fold = self.svm_param.k_fold
        acc_arr = []
        kf = KFold(n_splits=k_fold, shuffle=True,
                   random_state=self.svm_param.random_state)

        for train_index, test_index in kf.split(train_data):
            X_train, X_test = train_data[train_index], train_data[test_index]
            y_train, y_test = label[train_index], label[test_index]

            # Define and train SVM Classifier
            clf = SVC(C=self.svm_param.C, kernel=self.svm_param.kernel)
            clf.fit(X_train, y_train)
            acc = clf.score(X_test, y_test)
            acc_arr.append(acc)

        return np.mean(np.array(acc_arr))

    def evaluate(self, real_data: np.ndarray):
        initial = self.eval_param.initial
        epoch_map = np.zeros(self.eval_param.total_models)
        index = 0

        while initial <= self.eval_param.limit:
            generator = self.load_saved_model(self.eval_param.initial)
            gen_samples = self.generate(generator)

            train_data, label = self.make_train_data_with_label(
                real_data=real_data, gen_samples=gen_samples
            )

            mean_acc = self.svm(train_data=train_data, label=label)
            epoch_map[index] += mean_acc

            index += 1
            initial += self.eval_param.increment
        return epoch_map


@hydra.main(config_path=str(PROJECT_ROOT / 'conf'), config_name='default')
def main(cfg: omegaconf.DictConfig):
    logger.info('Loading dataset ...')
    datamodule = hydra.utils.instantiate(
        cfg.data.datamodule, _recursive_=False
    )
    data_samples, num_unique = datamodule.load_data()

    gan_evaluators = [
        hydra.utils.instantiate(
            cfg.gan_evaluate.evalmodule,
            svm_param=cfg.gan_evaluate.evalmodule.svm_param,
            modelmodule=cfg.model.modelmodule,
            trainer=cfg.train.trainer,
            datamodule=cfg.data.datamodule,
            num_opcode_unique=num_unique,
            _recursive_=False
        ) for _ in range(5)
    ]

    logger.info('Evaluating using multi-thread ...')
    my_timer = MyTimer()
    total = np.zeros(cfg.gan_evaluate.evalmodule.param.total_models)
    for count, evaluator in enumerate(gan_evaluators):
        logger.info(f'Evaluator #{count + 1} ...')
        total += evaluator.evaluate(data_samples)

    logger.info('Finished evaluating! '
                f'Execution time: {my_timer.get_execution_time()}')

    total /= 5
    logger.info('Best Model: {} -- Accuracy: {:.2f}'
                .format(np.argmin(total), np.min(total)))


if __name__ == '__main__':
    logger.propagate = False
    main()
