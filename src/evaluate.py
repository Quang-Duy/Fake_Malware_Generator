import logging
import os
from warnings import simplefilter

import coloredlogs
import hydra
import numpy as np
import omegaconf
from omegaconf import DictConfig
from tensorflow.keras.models import load_model

from src.common.utils import PROJECT_ROOT

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'


simplefilter(action='ignore', category=FutureWarning)

logger = logging.getLogger(__name__)
coloredlogs.install(level=logging.DEBUG, logger=logger)

logging.getLogger('matplotlib').setLevel(logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('h5py').setLevel(logging.ERROR)


def generate(generator, batch_size, latent_dim, factor, max_file_len):
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    gen_samples = generator.predict(noise)
    gen_samples = (gen_samples + 1) * factor
    gen_samples = np.rint(gen_samples)
    gen_samples = gen_samples.astype(int)
    gen_samples = np.reshape(gen_samples, (batch_size, max_file_len))
    return gen_samples


def load_generator(saved_dir: str = None):
    model_path = os.path.join(PROJECT_ROOT, saved_dir)
    model_file = None
    for file in os.listdir(model_path):
        if file.endswith('.hdf5'):
            model_file = file
            break

    if not model_file:
        raise FileNotFoundError(
            f"Model {model_path} was not found. Make sure you saved your "
            "best model after executing best_gan_evaluate.py")

    generator = load_model(os.path.join(
        PROJECT_ROOT, saved_dir, model_file)
    )
    return generator


def evaluate(cfg: DictConfig):
    batch_size = cfg.train.trainer.batch_size
    y = np.array([1] * batch_size + [0] * batch_size)

    datamodule = hydra.utils.instantiate(
        cfg.data.datamodule, _recursive_=False
    )
    real_samples, num_unique = datamodule.load_data()
    factor = num_unique / 2.

    logger.info(f'Loading {cfg.full_evaluate.evaluator.model} model ...')
    generator = load_generator(cfg.full_evaluate.evaluator.model_path)
    fake_samples = generate(
        generator=generator, batch_size=batch_size,
        latent_dim=cfg.model.modelmodule.model.latent_dim, factor=factor,
        max_file_len=cfg.data.datamodule.datasets.train.max_file_len
    )

    word2vec = hydra.utils.instantiate(
        cfg.word2vec.w2vmodule, real_samples=real_samples,
        batch_size=cfg.train.trainer.batch_size, _recursive_=False
    )
    X = word2vec.embed(fake_samples)

    rf_clf = hydra.utils.instantiate(
        cfg.random_forest.rfmodule, _recursive_=False
    )
    rf_clf.train_and_eval(X, y)


@hydra.main(config_path=str(PROJECT_ROOT / 'conf'), config_name='default')
def main(cfg: omegaconf.DictConfig):
    evaluate(cfg)


if __name__ == '__main__':
    logger.propagate = False
    main()
