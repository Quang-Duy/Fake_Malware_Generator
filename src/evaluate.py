import logging
import os
from warnings import simplefilter

import coloredlogs
import hydra
import numpy as np
import omegaconf
from omegaconf import DictConfig
from tensorflow.keras.models import load_model

from src.common.utils import PROJECT_ROOT

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'


simplefilter(action='ignore', category=FutureWarning)

logger = logging.getLogger(__name__)
coloredlogs.install(level=logging.DEBUG, logger=logger)

logging.getLogger('urllib3').setLevel(logging.ERROR)
logging.getLogger('matplotlib').setLevel(logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('h5py').setLevel(logging.ERROR)


def generate(generator, batch_size: int, latent_dim: int, factor,
             max_file_len: int, is_bert: bool = False):
    noise = np.random.normal(0, 1, (batch_size, latent_dim))
    gen_samples = generator.predict(noise)

    if not is_bert:
        gen_samples = (gen_samples + 1) * factor
        gen_samples = np.rint(gen_samples)
        gen_samples = gen_samples.astype(int)

    gen_samples = np.reshape(gen_samples, (batch_size, max_file_len))
    return gen_samples


def load_generator(saved_dir: str = None, is_bert: bool = False):
    model_path = os.path.join(PROJECT_ROOT, saved_dir)
    model_file = None
    file_end_with = '.hdf5' if not is_bert else '_bert.hdf5'

    for file in os.listdir(model_path):
        if file.endswith(file_end_with):
            model_file = file
            break

    if not model_file:
        raise FileNotFoundError(
            f"Model {model_path} was not found. Make sure you saved your "
            "best model after executing best_gan_evaluate.py")

    generator = load_model(os.path.join(
        PROJECT_ROOT, saved_dir, model_file)
    )
    return generator


def make_train_data(real_sample, fake_sample, batch_size: int):
    idx = np.random.randint(low=0, high=real_sample.shape[0],
                            size=batch_size)
    real = real_sample[idx]
    X = np.concatenate((real, fake_sample))
    return np.array(X)


def evaluate(cfg: DictConfig):
    batch_size = cfg.train.trainer.batch_size
    y = np.array([1] * batch_size + [0] * batch_size)

    tokenized = not cfg.full_evaluate.evaluator.is_bert
    datamodule = hydra.utils.instantiate(
        cfg.data.datamodule, _recursive_=False
    )
    real_samples, num_unique = datamodule.load_data(tokenized=tokenized)
    factor = num_unique / 2.

    logger.info(f'Loading {cfg.full_evaluate.evaluator.model} model ...')
    generator = load_generator(cfg.full_evaluate.evaluator.model_path,
                               is_bert=cfg.full_evaluate.evaluator.is_bert)
    fake_samples = generate(
        generator=generator, batch_size=batch_size,
        latent_dim=cfg.model.modelmodule.model.latent_dim, factor=factor,
        max_file_len=cfg.data.datamodule.datasets.train.max_file_len,
        is_bert=cfg.full_evaluate.evaluator.is_bert
    )

    if cfg.full_evaluate.evaluator.is_bert:
        distil_bert = hydra.utils.instantiate(
            cfg.bert.bertmodule, _recursive_=False
        )
        real_samples = real_samples[:200, :]
        real_samples = distil_bert.embed(real_samples)
        X = make_train_data(real_samples, fake_samples, batch_size=batch_size)

    if cfg.full_evaluate.evaluator.is_word2vec:
        word2vec = hydra.utils.instantiate(
            cfg.word2vec.w2vmodule, real_samples=real_samples,
            batch_size=cfg.train.trainer.batch_size, _recursive_=False
        )
        X = word2vec.embed(fake_samples)
    rf_clf = hydra.utils.instantiate(
        cfg.random_forest.rfmodule, _recursive_=False
    )
    rf_clf.train_and_eval(X, y)


@hydra.main(config_path=str(PROJECT_ROOT / 'conf'), config_name='default')
def main(cfg: omegaconf.DictConfig):
    evaluate(cfg)


if __name__ == '__main__':
    logger.propagate = False
    main()
