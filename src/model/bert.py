""" Create Distil-BERT for feature extraction

Usage

>>> python -m src.model.bert

"""

import hydra
import numpy as np
import omegaconf
import transformers as ppb

from src.common.utils import PROJECT_ROOT


class DistilBERT:
    def __init__(self, param):
        """ Initialize Distil-BERT model

        Args:
            param: distil-bert parameters from hydra config
        """
        self.param = param
        self.model_class = ppb.DistilBertModel
        self.tokenizer_class = ppb.DistilBertTokenizer

        self.tokenizer = self.tokenizer_class.from_pretrained(
            self.param.pretrained_weights
        )
        self.model = self.model_class.from_pretrained(
            self.param.pretrained_weights
        )

    def embed(self, sample):
        tokenized = []
        for opcode_list in sample:
            # Convert opcode list into sentence to feed in BERT tokenizer
            sentence = ' '.join(opcode_list)
            tokenized = np.concatenate(
                (tokenized, self.tokenizer.encode(
                    sentence, add_special_tokens=False)),
                axis=None
            )

        # Calculate new size that is divisible by `max_tokens` to reshape
        mod = len(tokenized) % self.param.max_tokens
        reshape_size = len(tokenized) - mod
        tokenized = tokenized[:reshape_size]

        # Divide into subset array of size `max_tokens`
        model_tokens = []
        while len(tokenized) > 0:
            model_tokens.append(tokenized[:self.param.max_tokens])
            tokenized = tokenized[self.param.max_tokens:]
        return np.array(model_tokens)


@hydra.main(config_path=str(PROJECT_ROOT / "conf"), config_name="default")
def main(cfg: omegaconf.DictConfig):
    distil_bert = hydra.utils.instantiate(
        cfg.bert.bertmodule, _recursive_=False
    )
    print("Success!") if distil_bert else print("Fail!")


if __name__ == '__main__':
    main()
