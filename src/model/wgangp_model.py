""" Create WGAN-GP model and its components

Usage

>>> python -m src.model.wgangp_model

"""

import os

import hydra
import keras.backend as K
import numpy as np
import omegaconf
from omegaconf import DictConfig
from tensorflow.keras.layers import (Add, BatchNormalization, Conv1D, Dense,
                                     Flatten, Input, LeakyReLU, Reshape)
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam, RMSprop

from src.common.utils import PROJECT_ROOT
from src.metrics import partial_loss, wasserstein_loss

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.chdir(PROJECT_ROOT)


class RandomWeightedAverage(Add):
    """ Weighted average between real and fake samples """

    def _merge_function(self, inputs):
        alpha = K.random_uniform((32, 1, 1))
        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])


class WGANGPModel:
    def __init__(self, model: DictConfig,
                 discriminator_param: DictConfig,
                 critic_param: DictConfig,
                 generator_param: DictConfig,
                 datamodule: DictConfig,
                 adam: bool = True) -> None:
        self.model = model
        self.critic_param = critic_param
        self.generator_param = generator_param
        self.datamodule = datamodule
        self.sample_shape = (self.datamodule.datasets.train.max_file_len, 1)

        if adam:
            optimizer = Adam(learning_rate=self.model.lr,
                             beta_1=self.model.beta_1,
                             beta_2=self.model.beta_2)
        else:
            optimizer = RMSprop(learning_rate=self.model.lr)

        # Build Generator and Critic
        self.generator = self.build_generator()
        self.critic = self.build_critic()

        # === Critic graph and compilation === #
        # Freeze generator while training critic
        self.generator.trainable = False

        # Real sample input
        real_sample = Input(shape=self.sample_shape)

        # Noise input
        z = Input(shape=(self.model.latent_dim,))

        # Generate fake sample based on noise
        fake_sample = self.generator(z)

        # Discriminator determines validity of the real and fake samples
        fake = self.critic(fake_sample)
        valid = self.critic(real_sample)

        # Construct weighted average between real and fake samples
        interpolated_sample = RandomWeightedAverage()([real_sample,
                                                       fake_sample])

        # Determine validity of weighted sample
        validity_interpolated = self.critic(interpolated_sample)

        # Define `partial` loss; Python partial provides loss function with
        # additional `averaged_samples` argument
        partial_gp_loss = partial_loss(interpolated_sample)

        # Define critic model
        self.critic_model = Model(inputs=[real_sample, z],
                                  outputs=[valid, fake, validity_interpolated])
        self.critic_model.compile(
            loss=[wasserstein_loss, partial_gp_loss],
            optimizer=optimizer,
            loss_weights=[1, 1, 10]
        )

        # === Generator graph and compilation === #
        # Freeze critic while training generator
        self.critic.trainable = False
        self.generator.trainable = True

        # Noise input
        z_gen = Input(shape=(self.model.latent_dim,))

        # Generate fake sample based on noise
        fake_sample = self.generator(z_gen)

        # Critic determines validity
        valid = self.critic(fake_sample)

        # Define generator model
        self.generator_model = Model(z_gen, valid)
        self.generator_model.compile(
            loss=wasserstein_loss, optimizer=optimizer
        )

    def build_generator(self):
        def build_block(model: Sequential, filters: int,
                        kernel_size: int, alpha: float, padding: str) -> None:
            model.add(Conv1D(
                filters=filters, kernel_size=kernel_size,
                activation=LeakyReLU(alpha=alpha), padding=padding)
            )
            model.add(
                BatchNormalization(momentum=self.generator_param.momentum)
            )

        model = Sequential(name='generator')

        model.add(Input(shape=(self.model.latent_dim,)))
        model.add(Reshape((self.model.latent_dim, 1)))

        build_block(model=model, filters=self.generator_param.filters,
                    kernel_size=self.generator_param.kernel_size,
                    alpha=self.generator_param.alpha,
                    padding=self.generator_param.padding)

        build_block(model=model, filters=self.generator_param.filters / 2,
                    kernel_size=self.generator_param.kernel_size,
                    alpha=self.generator_param.alpha,
                    padding=self.generator_param.padding)

        build_block(model=model, filters=self.generator_param.filters / 4,
                    kernel_size=self.generator_param.kernel_size,
                    alpha=self.generator_param.alpha,
                    padding=self.generator_param.padding)

        model.add(Flatten())
        model.add(Dense(np.product(self.sample_shape),
                        activation=self.generator_param.activation))
        model.add(Reshape(self.sample_shape))

        noise = Input(shape=(self.model.latent_dim,))
        output = model(noise)

        return Model(noise, output)

    def build_critic(self):

        model = Sequential(name='critic')
        model.add(
            Conv1D(filters=self.critic_param.filters,
                   kernel_size=self.critic_param.kernel_size,
                   activation=LeakyReLU(alpha=self.critic_param.alpha),
                   input_shape=self.sample_shape,
                   padding=self.critic_param.padding)
        )
        model.add(
            Conv1D(filters=self.critic_param.filters * 2,
                   kernel_size=self.critic_param.kernel_size,
                   activation=LeakyReLU(alpha=self.critic_param.alpha),
                   input_shape=self.sample_shape,
                   padding=self.critic_param.padding)
        )
        model.add(
            Conv1D(filters=self.critic_param.filters * 4,
                   kernel_size=self.critic_param.kernel_size,
                   activation=LeakyReLU(alpha=self.critic_param.alpha),
                   input_shape=self.sample_shape,
                   padding=self.critic_param.padding)
        )
        model.add(Flatten())
        model.add(Dense(self.critic_param.last_output))

        input = Input(shape=self.sample_shape)
        validity = model(input)

        return Model(input, validity)


@hydra.main(config_path=str(PROJECT_ROOT / 'conf'), config_name='default')
def main(cfg: omegaconf.DictConfig):
    model = hydra.utils.instantiate(
        cfg.model.modelmodule,
        datamodule=cfg.data.datamodule,
        _recursive_=False
    )
    print("Success!") if model else print("Fail!")


if __name__ == '__main__':
    main()
