""" Train and evaluate script to train WGAN-GP model, tune classifiers'
hyperparameters, and evaluate WGAN-GP model

Usage

>>> python -m src.train_and_eval

# Run MlFlow UI to view results
>>> mlflow ui

"""

import logging
import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import coloredlogs
from hydra import compose
import hydra
import mlflow
import tensorflow as tf
import numpy as np
import omegaconf
from omegaconf import DictConfig
from src.common.utils import PROJECT_ROOT

from src.training.train_wgangp import train
from src.tuning.tuning_classifiers import tune_classifier
from src.best_gan_evaluate import evaluate_wgangp
from src.common.utils import *

logger = logging.getLogger(__name__)
coloredlogs.install(level=logging.DEBUG, logger=logger)

logging.getLogger('git').setLevel(logging.ERROR)
logging.getLogger('urllib3').setLevel(logging.ERROR)
logging.getLogger('matplotlib').setLevel(logging.ERROR)
logging.getLogger('tensorflow').setLevel(logging.ERROR)
logging.getLogger('h5py').setLevel(logging.ERROR)


def train_and_eval(cfg: DictConfig) -> None:
    logger.info('Loading dataset ...')
    datamodule = hydra.utils.instantiate(
        cfg.data.datamodule, _recursive_=False
    )
    X_train = datamodule.prepare_data()
    X_train = X_train[:64]

    distil_bert = hydra.utils.instantiate(
        cfg.bert.bertmodule, _recursive_=False
    )

    logger.info('Embedding dataset ...')
    X_train = datamodule.embed_data(data=X_train, distil_bert=distil_bert)

    # Train WGAN-GP model
    # train(cfg=cfg, X_train=X_train, make_plot=True)

    # Create y_train for tuning hyperparameters for classifiers
    y_train = np.array([1] * len(X_train))

    param_config = cfg.train_and_eval.param_config
    optim_config = cfg.train_and_eval.optim_config
    eval_config = cfg.train_and_eval.eval_config
    clf_name = cfg.train_and_eval.classifier_name

    for name in clf_name:
        # Set all classifiers' usage to False
        clear_usage(
            param_config=os.path.join(PROJECT_ROOT, param_config),
            clf_name=clf_name
        )

        # Set the current classfier's usage to True
        set_usage(
            param_config=os.path.join(PROJECT_ROOT, param_config),
            clf_name=name
        )

        # Set experiment run name for tuning
        set_optim_run_name(
            file_path=os.path.join(PROJECT_ROOT, optim_config), clf_name=name
        )

        # Re-compose config files to get the latest changes before tuning
        cfg = compose(config_name='default')

        # Tune hyperparameters
        tune_classifier(cfg=cfg, X_train=X_train, y_train=y_train)

        # Set experiment run name for evaluation
        set_eval_run_name(
            file_path=os.path.join(PROJECT_ROOT, eval_config), clf_name=name
        )

        # Re-compose config files to get the latest changes before evaluating
        cfg = compose(config_name='default')

        # Evaluate WGAN-GP model
        evaluate_wgangp(cfg=cfg, real_data=X_train)


@hydra.main(config_path=str(PROJECT_ROOT / 'conf'), config_name='default')
def main(cfg: omegaconf.DictConfig):
    train_and_eval(cfg)


if __name__ == '__main__':
    logger.propagate = False
    logger.info("Num GPUs Available: "
                f"{len(tf.config.list_physical_devices('GPU'))}")
    main()
